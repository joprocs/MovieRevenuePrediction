{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Deutsch', 'English', 'Français']"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "line = data['spoken_languages'].iloc[500]\n",
    "arr = literal_eval(line)\n",
    "nnn = [lang['name'] for lang in arr]\n",
    "sorted(nnn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. find all langs that exist in training set\n",
    "# 2. encode each row of langs into a vector w/ len num of langs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_names(row, names):\n",
    "  [int(name in row )for name in names]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0]"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[int(lang in ['English']) for lang in sorted(list(lang_set))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lang_to_names(spoken_lang): # TODO: catch bad inputs\n",
    "  # convert string to array of dicts\n",
    "  arr = literal_eval(spoken_lang)\n",
    "  # create set from array of values for \"name\" property\n",
    "  lang_names = [lang['name'] for lang in arr]\n",
    "  return lang_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'',\n",
       " 'Afrikaans',\n",
       " 'Bahasa indonesia',\n",
       " 'Català',\n",
       " 'Dansk',\n",
       " 'Deutsch',\n",
       " 'Eesti',\n",
       " 'English',\n",
       " 'Español',\n",
       " 'Esperanto',\n",
       " 'Français',\n",
       " 'Gaeilge',\n",
       " 'Hrvatski',\n",
       " 'Italiano',\n",
       " 'Kiswahili',\n",
       " 'Latin',\n",
       " 'Magyar',\n",
       " 'Nederlands',\n",
       " 'No Language',\n",
       " 'Norsk',\n",
       " 'Polski',\n",
       " 'Português',\n",
       " 'Pусский',\n",
       " 'Română',\n",
       " 'Slovenčina',\n",
       " 'Somali',\n",
       " 'Srpski',\n",
       " 'Tiếng Việt',\n",
       " 'Türkçe',\n",
       " 'Wolof',\n",
       " 'euskera',\n",
       " 'isiZulu',\n",
       " 'shqip',\n",
       " 'suomi',\n",
       " 'svenska',\n",
       " 'Íslenska',\n",
       " 'Český',\n",
       " 'ελληνικά',\n",
       " 'Український',\n",
       " 'български език',\n",
       " 'қазақ',\n",
       " 'עִבְרִית',\n",
       " 'اردو',\n",
       " 'العربية',\n",
       " 'فارسی',\n",
       " 'پښتو',\n",
       " 'हिन्दी',\n",
       " 'বাংলা',\n",
       " 'ਪੰਜਾਬੀ',\n",
       " 'தமிழ்',\n",
       " 'తెలుగు',\n",
       " 'ภาษาไทย',\n",
       " '广州话 / 廣州話',\n",
       " '日本語',\n",
       " '普通话',\n",
       " '한국어/조선말'}"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "langs = data['genres'].dropna().apply(lang_to_names) #flatten\n",
    "flat_langs = [item for sublist in langs for item in sublist]\n",
    "lang_set = set(flat_langs)\n",
    "lang_set\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>belongs_to_collection</th>\n",
       "      <th>budget</th>\n",
       "      <th>genres</th>\n",
       "      <th>homepage</th>\n",
       "      <th>imdb_id</th>\n",
       "      <th>original_language</th>\n",
       "      <th>original_title</th>\n",
       "      <th>overview</th>\n",
       "      <th>popularity</th>\n",
       "      <th>...</th>\n",
       "      <th>release_date</th>\n",
       "      <th>runtime</th>\n",
       "      <th>spoken_languages</th>\n",
       "      <th>status</th>\n",
       "      <th>tagline</th>\n",
       "      <th>title</th>\n",
       "      <th>Keywords</th>\n",
       "      <th>cast</th>\n",
       "      <th>crew</th>\n",
       "      <th>revenue</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>[{'id': 313576, 'name': 'Hot Tub Time Machine ...</td>\n",
       "      <td>14000000</td>\n",
       "      <td>[{'id': 35, 'name': 'Comedy'}]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>tt2637294</td>\n",
       "      <td>en</td>\n",
       "      <td>Hot Tub Time Machine 2</td>\n",
       "      <td>When Lou, who has become the \"father of the In...</td>\n",
       "      <td>6.575393</td>\n",
       "      <td>...</td>\n",
       "      <td>2/20/15</td>\n",
       "      <td>93.0</td>\n",
       "      <td>[{'iso_639_1': 'en', 'name': 'English'}]</td>\n",
       "      <td>Released</td>\n",
       "      <td>The Laws of Space and Time are About to be Vio...</td>\n",
       "      <td>Hot Tub Time Machine 2</td>\n",
       "      <td>[{'id': 4379, 'name': 'time travel'}, {'id': 9...</td>\n",
       "      <td>[{'cast_id': 4, 'character': 'Lou', 'credit_id...</td>\n",
       "      <td>[{'credit_id': '59ac067c92514107af02c8c8', 'de...</td>\n",
       "      <td>12314651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>[{'id': 107674, 'name': 'The Princess Diaries ...</td>\n",
       "      <td>40000000</td>\n",
       "      <td>[{'id': 35, 'name': 'Comedy'}, {'id': 18, 'nam...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>tt0368933</td>\n",
       "      <td>en</td>\n",
       "      <td>The Princess Diaries 2: Royal Engagement</td>\n",
       "      <td>Mia Thermopolis is now a college graduate and ...</td>\n",
       "      <td>8.248895</td>\n",
       "      <td>...</td>\n",
       "      <td>8/6/04</td>\n",
       "      <td>113.0</td>\n",
       "      <td>[{'iso_639_1': 'en', 'name': 'English'}]</td>\n",
       "      <td>Released</td>\n",
       "      <td>It can take a lifetime to find true love; she'...</td>\n",
       "      <td>The Princess Diaries 2: Royal Engagement</td>\n",
       "      <td>[{'id': 2505, 'name': 'coronation'}, {'id': 42...</td>\n",
       "      <td>[{'cast_id': 1, 'character': 'Mia Thermopolis'...</td>\n",
       "      <td>[{'credit_id': '52fe43fe9251416c7502563d', 'de...</td>\n",
       "      <td>95149435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3300000</td>\n",
       "      <td>[{'id': 18, 'name': 'Drama'}]</td>\n",
       "      <td>http://sonyclassics.com/whiplash/</td>\n",
       "      <td>tt2582802</td>\n",
       "      <td>en</td>\n",
       "      <td>Whiplash</td>\n",
       "      <td>Under the direction of a ruthless instructor, ...</td>\n",
       "      <td>64.299990</td>\n",
       "      <td>...</td>\n",
       "      <td>10/10/14</td>\n",
       "      <td>105.0</td>\n",
       "      <td>[{'iso_639_1': 'en', 'name': 'English'}]</td>\n",
       "      <td>Released</td>\n",
       "      <td>The road to greatness can take you to the edge.</td>\n",
       "      <td>Whiplash</td>\n",
       "      <td>[{'id': 1416, 'name': 'jazz'}, {'id': 1523, 'n...</td>\n",
       "      <td>[{'cast_id': 5, 'character': 'Andrew Neimann',...</td>\n",
       "      <td>[{'credit_id': '54d5356ec3a3683ba0000039', 'de...</td>\n",
       "      <td>13092000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1200000</td>\n",
       "      <td>[{'id': 53, 'name': 'Thriller'}, {'id': 18, 'n...</td>\n",
       "      <td>http://kahaanithefilm.com/</td>\n",
       "      <td>tt1821480</td>\n",
       "      <td>hi</td>\n",
       "      <td>Kahaani</td>\n",
       "      <td>Vidya Bagchi (Vidya Balan) arrives in Kolkata ...</td>\n",
       "      <td>3.174936</td>\n",
       "      <td>...</td>\n",
       "      <td>3/9/12</td>\n",
       "      <td>122.0</td>\n",
       "      <td>[{'iso_639_1': 'en', 'name': 'English'}, {'iso...</td>\n",
       "      <td>Released</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Kahaani</td>\n",
       "      <td>[{'id': 10092, 'name': 'mystery'}, {'id': 1054...</td>\n",
       "      <td>[{'cast_id': 1, 'character': 'Vidya Bagchi', '...</td>\n",
       "      <td>[{'credit_id': '52fe48779251416c9108d6eb', 'de...</td>\n",
       "      <td>16000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>[{'id': 28, 'name': 'Action'}, {'id': 53, 'nam...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>tt1380152</td>\n",
       "      <td>ko</td>\n",
       "      <td>마린보이</td>\n",
       "      <td>Marine Boy is the story of a former national s...</td>\n",
       "      <td>1.148070</td>\n",
       "      <td>...</td>\n",
       "      <td>2/5/09</td>\n",
       "      <td>118.0</td>\n",
       "      <td>[{'iso_639_1': 'ko', 'name': '한국어/조선말'}]</td>\n",
       "      <td>Released</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Marine Boy</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[{'cast_id': 3, 'character': 'Chun-soo', 'cred...</td>\n",
       "      <td>[{'credit_id': '52fe464b9251416c75073b43', 'de...</td>\n",
       "      <td>3923970</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                              belongs_to_collection    budget  \\\n",
       "0   1  [{'id': 313576, 'name': 'Hot Tub Time Machine ...  14000000   \n",
       "1   2  [{'id': 107674, 'name': 'The Princess Diaries ...  40000000   \n",
       "2   3                                                NaN   3300000   \n",
       "3   4                                                NaN   1200000   \n",
       "4   5                                                NaN         0   \n",
       "\n",
       "                                              genres  \\\n",
       "0                     [{'id': 35, 'name': 'Comedy'}]   \n",
       "1  [{'id': 35, 'name': 'Comedy'}, {'id': 18, 'nam...   \n",
       "2                      [{'id': 18, 'name': 'Drama'}]   \n",
       "3  [{'id': 53, 'name': 'Thriller'}, {'id': 18, 'n...   \n",
       "4  [{'id': 28, 'name': 'Action'}, {'id': 53, 'nam...   \n",
       "\n",
       "                            homepage    imdb_id original_language  \\\n",
       "0                                NaN  tt2637294                en   \n",
       "1                                NaN  tt0368933                en   \n",
       "2  http://sonyclassics.com/whiplash/  tt2582802                en   \n",
       "3         http://kahaanithefilm.com/  tt1821480                hi   \n",
       "4                                NaN  tt1380152                ko   \n",
       "\n",
       "                             original_title  \\\n",
       "0                    Hot Tub Time Machine 2   \n",
       "1  The Princess Diaries 2: Royal Engagement   \n",
       "2                                  Whiplash   \n",
       "3                                   Kahaani   \n",
       "4                                      마린보이   \n",
       "\n",
       "                                            overview  popularity  ...  \\\n",
       "0  When Lou, who has become the \"father of the In...    6.575393  ...   \n",
       "1  Mia Thermopolis is now a college graduate and ...    8.248895  ...   \n",
       "2  Under the direction of a ruthless instructor, ...   64.299990  ...   \n",
       "3  Vidya Bagchi (Vidya Balan) arrives in Kolkata ...    3.174936  ...   \n",
       "4  Marine Boy is the story of a former national s...    1.148070  ...   \n",
       "\n",
       "  release_date runtime                                   spoken_languages  \\\n",
       "0      2/20/15    93.0           [{'iso_639_1': 'en', 'name': 'English'}]   \n",
       "1       8/6/04   113.0           [{'iso_639_1': 'en', 'name': 'English'}]   \n",
       "2     10/10/14   105.0           [{'iso_639_1': 'en', 'name': 'English'}]   \n",
       "3       3/9/12   122.0  [{'iso_639_1': 'en', 'name': 'English'}, {'iso...   \n",
       "4       2/5/09   118.0           [{'iso_639_1': 'ko', 'name': '한국어/조선말'}]   \n",
       "\n",
       "     status                                            tagline  \\\n",
       "0  Released  The Laws of Space and Time are About to be Vio...   \n",
       "1  Released  It can take a lifetime to find true love; she'...   \n",
       "2  Released    The road to greatness can take you to the edge.   \n",
       "3  Released                                                NaN   \n",
       "4  Released                                                NaN   \n",
       "\n",
       "                                      title  \\\n",
       "0                    Hot Tub Time Machine 2   \n",
       "1  The Princess Diaries 2: Royal Engagement   \n",
       "2                                  Whiplash   \n",
       "3                                   Kahaani   \n",
       "4                                Marine Boy   \n",
       "\n",
       "                                            Keywords  \\\n",
       "0  [{'id': 4379, 'name': 'time travel'}, {'id': 9...   \n",
       "1  [{'id': 2505, 'name': 'coronation'}, {'id': 42...   \n",
       "2  [{'id': 1416, 'name': 'jazz'}, {'id': 1523, 'n...   \n",
       "3  [{'id': 10092, 'name': 'mystery'}, {'id': 1054...   \n",
       "4                                                NaN   \n",
       "\n",
       "                                                cast  \\\n",
       "0  [{'cast_id': 4, 'character': 'Lou', 'credit_id...   \n",
       "1  [{'cast_id': 1, 'character': 'Mia Thermopolis'...   \n",
       "2  [{'cast_id': 5, 'character': 'Andrew Neimann',...   \n",
       "3  [{'cast_id': 1, 'character': 'Vidya Bagchi', '...   \n",
       "4  [{'cast_id': 3, 'character': 'Chun-soo', 'cred...   \n",
       "\n",
       "                                                crew   revenue  \n",
       "0  [{'credit_id': '59ac067c92514107af02c8c8', 'de...  12314651  \n",
       "1  [{'credit_id': '52fe43fe9251416c7502563d', 'de...  95149435  \n",
       "2  [{'credit_id': '54d5356ec3a3683ba0000039', 'de...  13092000  \n",
       "3  [{'credit_id': '52fe48779251416c9108d6eb', 'de...  16000000  \n",
       "4  [{'credit_id': '52fe464b9251416c75073b43', 'de...   3923970  \n",
       "\n",
       "[5 rows x 23 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from ast import literal_eval\n",
    "\n",
    "#metrics dependencies\n",
    "from sklearn.metrics import accuracy_score,recall_score,precision_score,f1_score\n",
    "\n",
    "#read train.csv\n",
    "data = pd.read_csv('train.csv')\n",
    "\n",
    "#display data\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#delete casts that are irrelevant\n",
    "data = data.drop(columns=\"original_language\")\n",
    "data = data.drop(columns=\"production_countries\")\n",
    "data = data.drop(columns=\"homepage\")\n",
    "#delete more\n",
    "data = data.drop(columns=\"imdb_id\")\n",
    "data = data.drop(columns= \"poster_path\")\n",
    "data = data.drop(columns= \"belongs_to_collection\")\n",
    "#delete rows where budget is 0\n",
    "data= data.loc[data[\"budget\"] != 0]\n",
    "#delete rows where revenue is 0\n",
    "data= data.loc[data[\"revenue\"] != 0]\n",
    "#display data dimensions\n",
    "data.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#separate the data columns into non-numerical and numerical\n",
    "data_numeric = data [['id','budget','popularity','runtime','revenue']]\n",
    "data_categorical = data[['genres','original_title','overview','production_companies','release_date','spoken_languages','tagline','title','Keywords','cast','crew']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#see unique values\n",
    "print(data['genres'].unique())\n",
    "print(data['original_title'].unique())\n",
    "print(data['overview'].unique())\n",
    "print(data['production_companies'].unique())\n",
    "print(data['release_date'].unique())\n",
    "print(data['spoken_languages'].unique())\n",
    "print(data['status'].unique())\n",
    "print(data['title'].unique())\n",
    "print(data['Keywords'].unique())\n",
    "print(data['cast'].unique())\n",
    "print(data['crew'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#genre encoding\n",
    "\n",
    "# treat null values\n",
    "data_categorical['genres'].fillna('NA', inplace = True)\n",
    "\n",
    "# separate all genres into one list, considering comma + space as separators\n",
    "genre = data_categorical['genres'].str.split(', ').tolist()\n",
    "\n",
    "# flatten the list\n",
    "flat_genre = [item for sublist in genre for item in sublist]\n",
    "\n",
    "# convert to a set to make unique\n",
    "set_genre = set(flat_genre)\n",
    "\n",
    "# back to list\n",
    "unique_genre = list(set_genre)\n",
    "\n",
    "# remove NA\n",
    "unique_genre.remove('NA')\n",
    "\n",
    "# create columns by each unique genre\n",
    "df = data_categorical.reindex(data_categorical.columns.tolist() + unique_genre, axis=1, fill_value=0)\n",
    "\n",
    "# for each value inside column, update the dummy\n",
    "for index, row in df.iterrows():\n",
    "    for val in row.genres.split(', '):\n",
    "        if val != 'NA':\n",
    "            df.loc[index, val] = 1\n",
    "\n",
    "df.drop('genres', axis = 1, inplace = True)  \n",
    "#df \n",
    "#df.drop(axis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#producion_companies encoding\n",
    "\n",
    "# treat null values\n",
    "data_categorical['production_companies'].fillna('NA', inplace = True)\n",
    "\n",
    "# separate all genres into one list, considering comma + space as separators\n",
    "production_companies = data_categorical['production_companies'].str.split(', ').tolist()\n",
    "\n",
    "# flatten the list\n",
    "flat_production_companies = [item for sublist in production_companies for item in sublist]\n",
    "\n",
    "# convert to a set to make unique\n",
    "set_production_companies = set(flat_production_companies)\n",
    "\n",
    "# back to list\n",
    "unique_production_companies = list(set_production_companies)\n",
    "\n",
    "# remove NA\n",
    "unique_production_companies.remove('NA')\n",
    "\n",
    "# create columns by each unique genre\n",
    "da = data_categorical.reindex(data_categorical.columns.tolist() + unique_production_companies, axis=1, fill_value=0)\n",
    "\n",
    "# for each value inside column, update the dummy\n",
    "for index, row in da.iterrows():\n",
    "    for val in row.production_companies.split(', '):\n",
    "        if val != 'NA':\n",
    "            da.loc[index, val] = 1\n",
    "\n",
    "da.drop('production_companies', axis = 1, inplace = True)  \n",
    "da "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#spoken_languages encoding\n",
    "data_categorical['spoken_languages'].fillna('NaN', inplace = True)\n",
    "\n",
    "# separate all genres into one list, considering comma + space as separators\n",
    "spoken_languages = data_categorical['spoken_languages'].str.split(', ').tolist()\n",
    "\n",
    "# flatten the list\n",
    "flat_spoken_languages = [item for sublist in spoken_languages for item in sublist]\n",
    "\n",
    "# convert to a set to make unique\n",
    "set_spoken_languages = set(flat_spoken_languages)\n",
    "\n",
    "# back to list\n",
    "unique_spoken_languages = list(set_spoken_languages)\n",
    "\n",
    "# remove NA\n",
    "#unique_spoken_languages.remove('NAN')\n",
    "\n",
    "# create columns by each unique genre\n",
    "ds = data_categorical.reindex(data_categorical.columns.tolist() + unique_spoken_languages, axis=1, fill_value=0)\n",
    "\n",
    "# for each value inside column, update the dummy\n",
    "for index, row in ds.iterrows():\n",
    "    for val in row.spoken_languages.split(', '):\n",
    "        if val != 'NA':\n",
    "            ds.loc[index, val] = 1\n",
    "\n",
    "ds.drop('spoken_languages', axis = 1, inplace = True)  \n",
    "ds\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#crew encoding\n",
    "\n",
    "# treat null values\n",
    "data_categorical['crew'].fillna('NaN', inplace = True)\n",
    "\n",
    "# separate all genres into one list, considering comma + space as separators\n",
    "crew = data_categorical['crew'].str.split(', ').tolist()\n",
    "\n",
    "# flatten the list\n",
    "flat_crew= [item for sublist in crew for item in sublist]\n",
    "\n",
    "# convert to a set to make unique\n",
    "set_crew = set(flat_crew)\n",
    "\n",
    "# back to list\n",
    "unique_crew = list(set_crew)\n",
    "\n",
    "# remove NA\n",
    "#unique_crew.remove('NA')\n",
    "\n",
    "# create columns by each unique genre\n",
    "dcr = data_categorical.reindex(data_categorical.columns.tolist() + unique_crew, axis=1, fill_value=0)\n",
    "\n",
    "# for each value inside column, update the dummy\n",
    "for index, row in dcr.iterrows():\n",
    "    for val in row.crew.split(', '):\n",
    "        if val != 'NaN':\n",
    "            dcr.loc[index, val] = 1\n",
    "\n",
    "dcr.drop('crew', axis = 1, inplace = True)  \n",
    "dcr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cast encoding\n",
    "\n",
    "#crashed Jordan's laptop\n",
    "\n",
    "# treat null values\n",
    "df['cast'].fillna('NA', inplace = True)\n",
    "\n",
    "# separate all cast members into one list, considering comma + space as separators\n",
    "genre = df['cast'].str.split(', ').tolist()\n",
    "\n",
    "# flatten the list\n",
    "flat_cast = [item for sublist in genre for item in sublist]\n",
    "\n",
    "# convert to a set to make unique\n",
    "set_cast = set(flat_cast)\n",
    "\n",
    "# back to list\n",
    "unique_cast = list(set_cast)\n",
    "\n",
    "# remove NA\n",
    "unique_cast.remove('NA')\n",
    "\n",
    "# create columns by each unique genre\n",
    "df = df.reindex(df.columns.tolist() + unique_cast, axis=1, fill_value=0)\n",
    "\n",
    "# for each value inside column, update the dummy\n",
    "for index, row in df.iterrows():\n",
    "    for val in row.column.split(', '):\n",
    "        if val != 'NA':\n",
    "            df.loc[index, val] = 1\n",
    "\n",
    "df.drop('cast', axis = 1, inplace = True)    \n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hot encoding/categorizing nonnumeric attempt\n",
    "#data_categorical_encoded = pd.get_dummies(data_categorical, prefix_sep='', drop_first=True)\n",
    "#data_categorical_encoded.head()\n",
    "#\n",
    "##testing\n",
    "#print(data_categorical_encoded.shape)\n",
    "#data_categorical_encoded.head()\n",
    "#\n",
    "##concat nonnumeric with numeric\n",
    "#data_new = pd.concat([data_numeric,data_categorical_encoded], axis=1)\n",
    "#data_new.head()\n",
    "\n",
    "#original encoding attempt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dummy classifer\n",
    "#X = data_new.drop(['budget'],axis=1)\n",
    "#y = data_new['budget']\n",
    "#\n",
    "##perform training and test split\n",
    "#from sklearn.model_selection import train_test_split\n",
    "#X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1)\n",
    "#\n",
    "##Dummy Classifier\n",
    "#from sklearn.dummy import DummyClassifier\n",
    "#clf = DummyClassifier(strategy= 'most_frequent').fit(X_train,y_train)\n",
    "#y_pred = clf.predict(X_test)\n",
    "#\n",
    "##Distribution of y test\n",
    "#print('y actual : \\n' +  str(y_test.value_counts()))\n",
    "#\n",
    "##Distribution of y predicted\n",
    "#print('y predicted : \\n' + str(pd.Series(y_pred).value_counts()))\n",
    "\n",
    "\n",
    "#tried using this, but it inlcuded every combination of descriptors as one feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Accuracy Score : ' + str(accuracy_score(y_test,y_pred)))\n",
    "print('Precision Score : ' + str(precision_score(y_test,y_pred, average='weighted')))\n",
    "print('Recall Score : ' + str(recall_score(y_test,y_pred, average='weighted')))\n",
    "print('F1 Score : ' + str(f1_score(y_test,y_pred, average='weighted')))\n",
    "\n",
    "#Dummy Classifier Confusion matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "print('Confusion Matrix : \\n' + str(confusion_matrix(y_test,y_pred)))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d8890a226e2761f88d95a8038a1f14698b6c31e67be2b51720271457a8accada"
  },
  "kernelspec": {
   "display_name": "Python 3.7.11 64-bit ('myenv': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
